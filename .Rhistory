created=h5createGroup("example.h5", "baa")
created=h5createGroup("example.h5", "foo/foobaa")
h5ls("example.h5")
A = matrix(1:10,nr=5,nc=2)
h5write(A, "example.h5", "foo/A")
B = array(seq(0.1,2.0,by=0.1), dim=c(5,2,2))
attr(B, "scale") <- "liter"
h5write(B, "example.h5", "foo/foobaa/B")
h5ls("example.h5")
df = data.frame(1L:5L,seq(0,1,length.out=5), c("ab", "cde", "fgh1", "a", "s"), stringAsFactors=FALSE)
h5write(df, "example.h5", "df")
h5ls("example.h5")
readA = h5read("example.h5","foo/A")
readB=h5read("example.h5","foo/foobaa/B")
readdf=h5read("example.h5","df")
readA
h5write(c(12,13,14),"example.h5","foo/A",index=list(1;3,1)
h5write(c(12,13,14),"example.h5","foo/A",index=list(1;3,1))
h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))
h5read("example.h5", "foo/A")
con = url("http://scholar.google.com/citations?user=HII60AAAAJ&hl=en")
htmlCode = readLines(con)
con = url("http://scholar.google.com/citations?user=HI-I60AAAAJ&hl=en")
htmlCode = readLines(con)
con = url("https://scholar.google.com/citations?user=HI-I6C0AAAAJ")
htmlCode = readLines(con)
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ")
htmlCode = readLines(con)
con = url("http://scholar.google.com/citations?user=HI-I6C0AAAAJ")
htmlCode= readLines(con)
close(con)
htmlCode
library(XML)
url <-"http://scholar.google.com/citations?user=HI-I6C0AAAAJ"
html <- htmlTreeParse(url, useInternalNodes = T)
xpathSApply((html, "//title", xmlValue()))
xpathSApply(html, "//title", xmlValue)
xpathSApply(html, "//td@id='col-citeby']", xmlValue)
xpathSApply(html, "//td[@id='col-citeby']", xmlValue)
library(httr); html2 = GET(url)
content2 = content(html2, as="text")
parsedHtml = htmlParse(content2, astext=TRUE)
parsedHtml = htmlParse(content2,asText=TRUE)
xpathASpply(parsedHtml, "//title", xmlValue())
xpathASpply(parsedHtml, "//title", xmlValue)
xpathSApply(parsedHtml, "//title", xmlValue)
pg1=GET("http://httpbin.org/basic-auth/user/passwd")
pg1
pg1
pg2=GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user","passwd"))
pg2
names(pg2)
google = handle("http://google.com")
pg1 = GET(handle=google, path="/")
pg2 = GET(handle=google, path="search")
pg2
install.packages("jpeg")
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github",
key = "56b637a5baffac62cad9",
secret = "8e107541ae1791259e9987d544ca568633da2ebf")
myapp
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
oauth_endpoints("github")
myapp ", secret = "05e4212b712bdab69fa62ff4cc9ccf41c324e09b")
myapp "test", secret = "05e4212b712bdab69fa62ff4cc9ccf41c324e09b")
myapp test, secret = "05e4212b712bdab69fa62ff4cc9ccf41c324e09b")
asc <- read.csv("getdata_data_ss06pid.csv")
asc
sqldf("select pwgtp1 from acs where AGEP < 50")
install.packages("sqldf")
sqldf("select pwgtp1 from acs where AGEP < 50")
library(sqldf)
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1 from acs where AGEP < 50")
asc <- read.csv("getdata_data_ss06pid.csv")
sqldf("select pwgtp1 from acs where AGEP < 50")
acs <- read.csv("getdata_data_ss06pid.csv")
acs
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select * from acs where AGEP < 50 and pwgtp1")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select distinct AGEP from acs")
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for'
file.dest <- 'getdata.for'
download.file(file.url, file.dest)
getdata <- read.fwf('getdata.for', skip=4, widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(getdata)
sum(getdata$V4)
file.url <- 'http://biostat.jhsph.edu/~jleek/contact.html'
file.dest <- 'contact.html'
download.file(file.url, file.dest)
con <- file('contact.html')
lines <- readLines(con)
l10 <- lines[10]
l20 <- lines[20]
l30 <- lines[30]
l100 <- lines[100]
nchar(l10)
nchar(l20)
nchar(l30)
nchar(l100)
library(httr)
oauth_endpoints("github")
myapp <- oauth_app("github", key="7eeb5753524e12ead876", secret="ef33989a51346e93a46ceecc743e6e302fdfe953")
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
download.file(url = "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv",
destfile = "q2.csv",
method = "curl")
library(sqldf)
acs <- read.csv("q2.csv", header=TRUE)
ucscDb <- dbConnect(MySQL(), user = "genome", host = "genome-mysql.csc.ucsc.edu")
library(RMySQL)
ucscDb <- dbConnect(MySQL(), user = "genome", host = "genome-mysql.csc.ucsc.edu")
ucscDb <- dbConnect(MySQL(), user = "genome", host = "http://genome-mysql.csc.ucsc.edu")
ucscDb <- dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
ucscDb
ucscDb <- dbConnect(MySQL(), user = "genome", host = "genome-mysql.cse.ucsc.edu")
set.seed(13435)
X <-data.frame("var1"=sample(1:5),"var2"=sample(6:10),"var3"=sample(11:15))
X <- X[sample(1:5),];X$var2[c(1,3)]=NA
X
X[,1]
X[,"var1"]
X[1:2, "var2"]
X[(X$var1 <=3 & X$var3 >11),]
X[(X$var1 <=3 & X$var3 >15),]
X[(X$var1 <=3 | X$var3 >15),]
X[which(X$var2 >8),]
sort(X$var1)
sort(X$var1,decreasing = TRUE)
sort(X$var2,na.last = TRUE)
X[order(X$var1),]
X[order(X$var1, X$var3),]
install.packages("plyr")
library(plyr)
arrange(X,var1)
arrange(X,desc(var1))
X$var4 <-rnorm(5)
X
Y <-cbind(X,rnorm(5))
Y
if(!file.exists("./data")){dir.create("./data")}
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile = ./data/restaurants.csv, method = "curl")
download.file(fileURL,destfile =restaurants.csv, method = "curl")
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile =restaurants.csv, method = "curl")
library(curl)
if(!file.exists("./data")){dir.create("./data")}
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile =restaurants.csv, method = "curl")
download.file(fileURL,destfile ="restaurants.csv", method = "curl")
restData <-read.csv('restaurants.csv"")
)
)
""
)
)
"")
}
)
skl
)
)
reset
reset_config()
))))))))))
""
)
)
end
""""""
]\
getwd()
fileURL <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile = "restaurant.csv",method = "curl")
library(curl)
download.file(fileURL,destfile = "restaurant.csv",method = "curl")
restData <read.csv("restaurant.csv")
restData <-read.csv("restaurant.csv")
if(!file.exists("./data")){dir.create("./data"")}
)
""
if(!file.exists("./data")){dir.create("./data)}
fileURL <- "https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
if(!file.exists("./data")){dir.create("./data")}
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile = "./data/restaurants.csv",method="curl")
restData <-read.csv("./data/restaurants.csv")
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile = "restaurants.csv",method="curl")
restData <-read.csv("./data/restaurants.csv")
restData <-read.csv("\restaurants.csv")
restData <-read.csv("restaurants.csv")
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile = "restaurants.csv",method="curl")
library(curl)
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile = "restaurants.csv",method="curl")
if(!file.exists("./data")){dir.create("./data")}
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile ="./data/restaurants.csv",method="curl")
fileURL <-"http://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile ="./data/restaurants.csv",method="curl")
if(!file.exists("./data")){dir.create("./data")}
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile ="./data/restaurants.csv",method="curl")
fileURL <-"http://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile ="./data/restaurants.csv",method="curl")
restData <-read.csv("restaurants.csv")
fileURL <-"https://data.baltimorecity.gov/api/views/k5ry-ef3g/rows.csv?accessType=DOWNLOAD"
download.file(fileURL,destfile ="./data/restaurants.csv",method="curl")
restData <-read.csv("Restaurants.csv")
restData <-read.csv("Restaurants.csv")
head(restData,n=3)
tail(restData,n=3)
summary(restData)
str(restData)
quantile(restData$councilDistrict,na.tm=TRUE)
quantile(restData$councilDistrict,probs = c(0.5,0.75,0.9))
table(restData$zipCode,useNA="ifany)
")"
""
table(restData$zipCode,useNA="ifany")
quantile(restData$councilDistrict,restData$zipCode)
table(restData$councilDistrict,restData$zipCode)
sum(is.na(restData$councilDistrict))
any(is.na(restData$councilDistrict))
all(restData$zipCode > 0)
colSums(is.na(restData))
all(colSums(is.na(restData))==0)
table(restData$zipCode %in% c("21212"))
table(restData$zipCode %in% c("21212", "21213"))
restData[restData$zipCode %in% ("21212", "21213"),]
restData[restData$zipCode %in% ("21212","21213"),]
restData[restData$zipCode %in% c("21212","21213"),]
data("UCBAdmissions")
DF = as.data.frame(UCBAdmissions)
summary(DF)
xt <- xtabs(Freq ~ Gender + Admit, data=DF)
xt
warpbreaks$replicate <-rep(1:9, len=54)
xt = xtabs(breaks~.,data=warpbreaks)
xt
fakeData = rnorm(le5)
fakeData = rnorm(1e5)
object.size(fakeData)
print(object.size(fakeData),units="Mb")
s1 <- seq(1,10,by=2); s1
s2 <- seq(1,10,length=3); s2
x <-c(1,3,8,25,100); seq(along=x)
restData$nearMe = RestData$neighborhood %in% c("Rowland Park", "Homeland")
restData$nearMe = restData$neighborhood %in% c("Rowland Park", "Homeland")
table(restData$nearMe)
restData$nearMe = restData$neighborhood %in% c("Roland Park", "Homeland")
table(restData$nearMe)
restData$zipWrong = ifelse(restData$zipCode <0, TRUE, FALSE)
table(restData$zipWrong,restData$zipCode <0)
table(restData$zipWrong, restData$zipCode < 0)
restData$zipGroups = cut(restData$zipCode,breaks=quantile(restData$zipCode))
table(restData$zipGroups)
table(restData$zipGroups, restData$zipCode)
library(Hmisc)
install.packages("Hmisc")
library(Hmisc)
library(Hmisc)
restData$zipGroups = cut2(restData$zipCode,g=4)
table(restData$zipGroups)
restData$zcf <- factor(restData$zipCode)
restData$zcf[1:10]
class(restData$zcf)
yesno <-sample(c("yes","no"),size=10,replace=TRUE)
yesnofac = factor(yesno,levels=c("yes","no"))
relevel(yesno,ref="yes")
relevel(yesnofac,ref="yes")
as.numeric(yesnofac)
library(Hmisc); library(plyr)
restData2=mutate(restData,zipGroups=cut2(zipCode,g=4))
table(restData2$zipGroups)
abs(restData)
library(reshape2)
head(mtcars)
mtcars$carname <- rownames(mtcars)
carMelt <-melt(mtcars,id=c("carname","gear","cyl"),measure.vars = c("mpg","hp"))
head(carMelt,n=3)
tail(carMelt,n=3)
cylData <-dcast(carMelt, cyl ~ variable)
cylData
cylData <- dcast(carMelt, cyl ~ variable,mean
)
cylData
head(InsectSprays)
tapply(InsectSprays$count,InsectSprays$spray,sum)
spIns = split(InsectSprays$count,InsectSprays$spray)
spIns
sprCount = lapply(spIns,sum)
sprCount
unlist(sprCount)
sapply(spIns,sum)
ddply(InsectSprays,.(spray),summarize,sum=sum(count))
spraySums <-ddply(InsectSprays,.(spray),summarize,sum=ave(count,FUN=sum)
)
dim(spraySums)
head(spraySums)
library(dplyr)
options(width = 105)
chicago <- readRDS("chicago.rds)
")"
)
""
chicago <- readRDS("chicago.rds")
chicago
dim(chicago)
str(chicago)
names(chicago)
head(select(chicago, city:dptp))
head(select(chicago, -(city:dptp))
)
chic.f <- filter(chicago, pm25tmean2 > 30)
head(chic.f, 10)
chic.f <-filter(chicago, pm25tmean2 > 30 & tmpd > 80)
head(chic.f)
count
count(chic.f)
chicago <- arrange(chicago, data)
chicagoar <- arrange(chicago, data)
chicago <- arrange(chicago, date)
head(chicago)
tail(chicago)
chicago <- arrange(chicago, desc(date)
)
hehad(chicago)
head(chicago)
tail(chicago)
chicago <- rename(chicago)
chicago <- rename(chicago, pm25=pm25tmean2, dewpoint=dptp)
head(chicago)
chicago <- mutate(chicago, pm25detrend=pm25-mean(pm25, na.mean=TRUE))
head(chicago)
head(select(chicago, pm25, pm25detrend))
chicago <- mutate(chicago,tempcat = factor(1*(tmpd>80), labels = c("cold", "hot")))
hotcold ,- group_by(chicago, tempcat)
hotcold <- group_by(chicago, tempcat)
summarize(hotcold, pm25 = mean(pm25), o3 = max(o3tmean2), no2 = median(no2tmean2))
summarize(hotcold, pm25 = mean(pm25, na.rm=TRUE), o3 = max(o3tmean2), no2 = median(no2tmean2))
chicago <- mutate(chicago, year = as.POSIXlt(date)$year + 1900)
years <- group_by(chicago, year)
summarize(years, pm25 = mean(pm25, na.rm = TRUE), o3=max(o3tmean2), no2=median(no2tmean2))
chicago %>% mutate(month = as.POSIXlt(date)$mon + 1) %>% group_by(month) %>% summarize(pm25=mean(pm25, na.rm=TRUE), o3=max(o3tmean2), no2=median(no2tmean2))
fileURL1 = "https://dl.dropboxusercontent.com/u/7710864/data/reviews-apr29.csv"
fileURL2 = "https://dl.dropboxusercontent.com/u/7710864/data/solutions-apr29.csv"
download.file(fileURL1,destfile = "./data/reviews.csv",method="curl"")
)
""
download.file(fileURL1,destfile = "./data/reviews.csv",method="curl")
library(curl)
download.file(fileURL1,destfile = "./data/reviews.csv",method="curl")
download.file(fileURL1,destfile = "reviews.csv",method="curl")
reviews=read.csv("reviews.csv"); solutions <-read.csv("solutions")
reviews=read.csv("reviews.csv"); solutions <-read.csv("solutions")
reviews=read.csv("reviews.csv"); solutions <-read.csv("solutions.csv")
head(reviews,2)
head(solutions,2)
names(reviews)
names(solutions)
mergedData = merge(reviews,solutions,by.x = "solution_id",by.y = "id", all= TRUE)
head(mergedData)
intersect(names(solutions),names(reviews))
mergedData2 = merge(reviews,solutions,all=TRUE)
head(mergedData2)
df1 = data.frame(id=sample(1;10),x=rnorm(10))
df1 = data.frame(id=sample(1:10),x=rnorm(10))
df2 = data.frame(id=sample(1:10),y=rnorm(10))
arrange(join(df1,ddf2),id)
arrange(join(df1,df2),id)
df3 = data.frame(id=sample(1:10),z=rnorm(10))
dfList=list(df1,df2,df3)
join_all(dfList)
ACS <- read.csv('ACS.csv')
ACS$agricultureLogical <- ifelse(ACS$ACR==3 & ACS$AGS==6,TRUE,FALSE)
which(ACS$agricultureLogical)
library(jpeg)
picture <- readJPEG('jeff.jpg', native=TRUE)
picture <- readJPEG('getdata_jeff.jpg', native=TRUE)
quantile(picture, probs = c(0.3, 0.8) )
rowNames <- seq(10,200, 2)
gdp <- read.csv('GDP.csv', header=F, skip=5, nrows=190)
View(gdp)
fed <- read.csv('GDP2.csv')
View(fed)
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
combined[with(combined, order(-V2) )]
mean(combined[combined$Income.Group=='High income: OECD',]$V2)
mean(combined[combined$Income.Group=='High income: nonOECD',]$V2)
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
combined <- merge(gdp, fed, by.x='V1', by.y='CountryCode', sort=TRUE)
View(combined)
combined[with(combined, order(-V2) )]
X=CountryCode
numbersAsText <- c("10", "100", "11", "9","1000")
nAsFactors <- as.factor(numbersAsText)
convert2number <- as.numeric(nAsFactors)
convertViacharacter <- as.numeric(as.character(nAsFactors))
sum(convertViacharacter)
convert2number
convertViacharacter
gdp <- read.csv("gdp.csv", header = TRUE, skip = 3, sep = ",")
gdp2 <- read.csv("GDP2.csv", header = TRUE)
gdp <- read.csv("GDP.csv", header = TRUE, skip = 3, sep = ",")
GDP <- GDP[2:191, c(1,2,4,5)]
rownames(GDP) <- NULL
GDP <- rename(GDP, CountryCode = X)
GDP <- GDP[2:191, c(1,2,4,5)]rownames(GDP) <- NULLGDP <- rename(GDP, CountryCode = X)
GDP <- GDP[2:191, c(1,2,4,5)]rownames(GDP) <- NULL
GDP <- GDP[2:191, c(1,2,4,5)]
gdp <- gdp[2:191, c(1,2,4,5)]
rownames(gdp) <- NULL
gdp <- rename(gdp, CountryCode = X)
gdp_merge <- join(gdp, gdp2)
sum(!is.na(unique(gdp_merge$Ranking)))
gdp_merge$Ranking <- as.numeric(as.character(gdp_merge$Ranking))
gdp_merge <- arrange(gdp_merge, desc(Ranking))
gdp_merge[13,3]
gdp_merge <- arrange(gdp_merge, desc(Ranking))
swirl()
library(swirl)
siwlr()
swirl()
avg_bytes = mean(size))
avg_bytes = mean(size) )
)
submit()
library(datasets)
data(cars)
with(cars, plot(speed, dist))
with(cars, plot(speed, dist))
library(lattice)
state<-data.frame(state.x77, region=state.region)
xyplot(Life.Exp ~ Income | region, data=state, layout=c(4,1))
library(ggplot2)
data(mpg)
qplot(displ, hwy, data=mpg)
library(datasets)
hist(airquality$Ozone)
library(datasets)
with(airquality, plot(Wind, Ozone))
library(datasets)
airquality <- transform(airquality, Month=factor(months))
airquality <- transform(airquality, Month=factor(Month))
boxplot(Ozone ~ Month, airquality, xlab="Month", ylab="Ozone (ppb)")
par("lty")
library(datasets)
with(airquality, plot(Wind, Ozone))
title(main="Ozone and Wind in NYC")
with(airquality, plot(Wind, Ozone, main="Ozone and Wind in NYC"))
with(subset(airquality, Month==5), points(Wind, Ozone, col="blue"))
with(subset(airquality, Month !=5 ), points(Wind, Ozone, col="red"))
legend("topright", pch=1, col=c("blue", "red"), legend=c("May", "Other Months"))
with(airquality, plot(Wind, Ozone, main="Ozone and Wind in NYC", type="n"))
with(subset(airquality, Month==5), points(Wind, Ozone, col="blue"))
with(subset(airquality, Month !=5 ), points(Wind, Ozone, col="red"))
legend("topright", pch=1, col=c("blue", "red"), legend=c("May", "Other Months"))
with(airquality, plot(Wind, Ozone, main="Ozone and Wind in NYC", pch="20"))
model<-lm(Ozone ~ Wind, airquality)
abline(model, lwd=2)
with(airquality, plot(Wind, Ozone, main="Ozone and Wind in NYC", pch=20))
model<-lm(Ozone ~ Wind, airquality)
abline(model, lwd=2)
par(mfrow=c(1,2))
with(airquality, {plot(Wind, Ozone, main="Ozone and Wind")plot(Solar.R, Ozone, main="Ozone and Solar Radiation")})
with(airquality, {plot(Wind, Ozone, main="Ozone and Wind")plot(Solar.R, Ozone, main="Ozone and Solar Radiation")})
with(airquality, {plot(Wind, Ozone, main="Ozone and Wind") plot(Solar.R, Ozone, main="Ozone and Solar Radiation")})
with(airquality, {plot(Wind, Ozone, main="Ozone and Wind") plot(Solar.R, Ozone, main="Ozone and Solar Radiation")})
with(airquality, {
plot(Wind, Ozone, main="Ozone and Wind")
plot(Solar.R, Ozone, main="Ozone and Solar Radiation")
})
Solar.R
setwd("~/EDA-project1")
ata/
dataFile <- "household_power_consumption.txt"
data <- read.table(dataFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subSetData <- data[data$Date %in% c("1/2/2007","2/2/2007") ,]
#str(subSetData)
globalActivePower <- as.numeric(subSetData$Global_active_power)
png("plot1.png", width=480, height=480)
hist(globalActivePower, col="red", main="Global Active Power", xlab="Global Active Power (kilowatts)")
dev.off()
dataFile <- "household_power_consumption.txt"
data <- read.table(dataFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subSetData <- data[data$Date %in% c("1/2/2007","2/2/2007") ,]
globalActivePower <- as.numeric(subSetData$Global_active_power)
png("plot1.png", width=480, height=480)
hist(globalActivePower, col="red", main="Global Active Power", xlab="Global Active Power (kilowatts)")
dev.off()
hist(globalActivePower, col="red", main="Global Active Power", xlab="Global Active Power (kilowatts)")
dev.off()
dataFile <- "household_power_consumption.txt"
data <- read.table(dataFile, header=TRUE, sep=";", stringsAsFactors=FALSE, dec=".")
subSetData <- data[data$Date %in% c("1/2/2007","2/2/2007") ,]
#str(subSetData)
globalActivePower <- as.numeric(subSetData$Global_active_power)
png("plot1.png", width=480, height=480)
hist(globalActivePower, col="red", main="Global Active Power", xlab="Global Active Power (kilowatts)")
dev.off()
